# âš™ï¸ Configuration

Configure the Epguides API using environment variables.

!!! tip "Quick Setup"
    Copy `.env.example` to `.env` and customize for your environment.

---

## ğŸ“‹ Environment Variables

### ğŸ—„ï¸ Redis

| Variable | Default | Description |
|----------|---------|-------------|
| `REDIS_HOST` | `redis` | Redis server hostname |
| `REDIS_PORT` | `6379` | Redis server port |
| `REDIS_DB` | `0` | Redis database number |
| `REDIS_PASSWORD` | - | Redis password (optional) |
| `REDIS_MAX_CONNECTIONS` | `100` | Max pool connections (~10 per worker) |

### â±ï¸ Cache

| Variable | Default | Description |
|----------|---------|-------------|
| `CACHE_TTL_SECONDS` | `604800` | Default cache TTL (7 days) |

### ğŸŒ API

| Variable | Default | Description |
|----------|---------|-------------|
| `API_BASE_URL` | `http://localhost:3000/` | Base URL for generated links |

### ğŸ¤– LLM (Optional)

| Variable | Required | Description |
|----------|:--------:|-------------|
| `LLM_ENABLED` | âšª | Set to `true` to enable NLQ |
| `LLM_API_URL` | If enabled | OpenAI-compatible API endpoint |
| `LLM_API_KEY` | If needed | API key for authentication |

### ğŸ“ Logging

| Variable | Default | Description |
|----------|---------|-------------|
| `LOG_LEVEL` | `INFO` | Log level (DEBUG, INFO, WARNING, ERROR) |
| `LOG_REQUESTS` | `true` | Enable request logging |

---

## ğŸ“„ Example `.env`

=== "Development"

    ```bash
    # Redis (local Docker)
    REDIS_HOST=redis
    REDIS_PORT=6379
    REDIS_PASSWORD=
    
    # API
    API_BASE_URL=http://localhost:3000/
    
    # Logging (verbose for debugging)
    LOG_LEVEL=DEBUG
    LOG_REQUESTS=true
    ```

=== "Production"

    ```bash
    # Redis (production)
    REDIS_HOST=redis
    REDIS_PORT=6379
    REDIS_PASSWORD=your-secure-password
    REDIS_MAX_CONNECTIONS=100
    
    # API
    API_BASE_URL=https://your-domain.com/
    
    # LLM (optional)
    LLM_ENABLED=true
    LLM_API_URL=https://api.openai.com/v1
    LLM_API_KEY=sk-your-api-key
    
    # Logging (less verbose)
    LOG_LEVEL=WARNING
    LOG_REQUESTS=false
    ```

---

## ğŸ¤– LLM Provider Examples

!!! abstract "OpenAI-Compatible APIs"
    The LLM feature works with any OpenAI-compatible API.

=== "OpenAI"

    ```bash
    LLM_API_URL=https://api.openai.com/v1
    LLM_API_KEY=sk-...
    ```

=== "Azure OpenAI"

    ```bash
    LLM_API_URL=https://your-resource.openai.azure.com/openai/deployments/your-deployment
    LLM_API_KEY=your-azure-key
    ```

=== "Ollama (Local)"

    ```bash
    LLM_API_URL=http://localhost:11434/v1
    LLM_API_KEY=  # Not required
    ```

=== "Self-hosted"

    ```bash
    # vLLM, text-generation-inference, etc.
    LLM_API_URL=https://your-llm-server.com/v1
    LLM_API_KEY=your-key
    ```

---

## âš¡ Caching Strategy

!!! info "Smart Caching"
    The API uses intelligent caching to minimize external requests while keeping data fresh.

### â° Cache Durations

| Data Type | Duration | Rationale |
|-----------|----------|-----------|
| âœ… Finished shows | **1 year** | Data won't change |
| ğŸ“‹ Shows master list | **30 days** | New shows added infrequently |
| â–¶ï¸ Ongoing shows | **7 days** | Episodes air weekly at most |

### ğŸ“Š Cache Flow

```
Request comes in
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Yes   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚refresh= â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Fetch fresh â”‚
â”‚  true?  â”‚        â”‚    data     â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚ No
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Yes   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚In cache?â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚Return cachedâ”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚ No
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Fetch from â”‚
â”‚external   â”‚
â”‚APIs       â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Yes
â”‚Show has  â”‚â”€â”€â”€â”€â”€â”€â–¶ Cache 1 year (finished)
â”‚end_date? â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚ No
     â–¼
Cache 7 days (ongoing)
```

### ğŸ”„ Automatic Behaviors

| Feature | Behavior |
|---------|----------|
| âœ… **Finished Shows** | When `end_date` is set, cache extends to 1 year |
| ğŸ”„ **Manual Refresh** | Use `?refresh=true` to bypass cache |
| â° **Smart `/next`** | Auto-refreshes when cached episode date has passed |

---

## âœ… Verification

### ğŸ’š Check API Health

```bash
curl "https://epguides.frecar.no/health"
```

### ğŸ¤– Check LLM Status

```bash
curl "https://epguides.frecar.no/health/llm"
```

Expected response when configured:

```json
{
  "enabled": true,
  "configured": true,
  "api_url": "https://api.openai.com/v1"
}
```
